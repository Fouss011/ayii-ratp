# app/routes/map.py
# (optionnel) """Docstring module..."""

from __future__ import annotations  # ‚Üê doit √™tre tout en haut

from fastapi import (
    APIRouter, Depends, HTTPException, Query, Response, Request, Header,
    UploadFile, File, Form, Body
)
from pydantic import BaseModel
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import text
from typing import Optional, Any, List
from uuid import UUID
from datetime import datetime, timezone
import os, uuid, mimetypes, io, csv, json, time

from app.db import get_db
from app.config import BASE_PUBLIC_URL, STATIC_DIR, STATIC_URL_PATH  # constants only (no circular import)

router = APIRouter()

# Si Python < 3.10, d√©-commente la ligne suivante et remplace l‚Äôannotation de _signed_cache plus bas
# from typing import Dict, Tuple

# ---- Supabase URL signer ----
import os
import httpx

async def _supabase_sign_url(public_or_path: str, expires_sec: int = 300) -> str | None:
    """
    Prend une URL publique Supabase OU juste un chemin, et renvoie une URL sign√©e.
    Si Supabase n‚Äôest pas configur√© ‚Üí None.
    """
    supa_url = (os.getenv("SUPABASE_URL") or "").rstrip("/")
    supa_key = (
        os.getenv("SUPABASE_SERVICE_ROLE")
        or os.getenv("SUPABASE_SERVICE_KEY")
        or os.getenv("SUPABASE_ANON_KEY")
    )
    bucket = os.getenv("SUPABASE_BUCKET", "attachments")

    # si on n'a pas au moins l'URL et une cl√© ‚Üí on ne signe pas
    if not supa_url or not supa_key:
      # tu peux logger ici si tu veux
      return None

    # normaliser le chemin √† signer
    if "/storage/v1/object/public/" in public_or_path:
        # on a re√ßu une URL compl√®te
        try:
            after = public_or_path.split("/storage/v1/object/public/")[1]
        except Exception:
            return None
    else:
        # on a re√ßu juste le chemin
        p = public_or_path.strip().lstrip("/")
        # on s'assure que √ßa commence par le bucket
        after = p if p.startswith(bucket + "/") else f"{bucket}/{p}"

    sign_endpoint = f"{supa_url}/storage/v1/object/sign/{after}"

    try:
        headers = {
            "Authorization": f"Bearer {supa_key}",
            "Content-Type": "application/json",
        }
        payload = {"expiresIn": int(expires_sec)}
        async with httpx.AsyncClient(timeout=10) as client:
            r = await client.post(sign_endpoint, headers=headers, json=payload)

        if r.status_code not in (200, 201):
            # ici pareil tu peux logger r.text
            return None

        data = r.json()
        signedURL = data.get("signedURL") or data.get("signedUrl")
        if not signedURL:
            return None

        # on reconstruit une URL compl√®te
        return (f"{supa_url}/storage/v1/{signedURL}").replace(
            "/storage/v1//", "/storage/v1/"
        )
    except Exception:
        return None

# Si Python ‚â• 3.10
_signed_cache: dict[str, tuple[float, str]] = {}  # url -> (expires_at, signed_url)
# Si Python < 3.10, utilise plut√¥t :
# _signed_cache: Dict[str, Tuple[float, str]] = {}

async def get_signed_cached(url: str, cache_ttl: int = 60, link_ttl_sec: int = 300) -> str | None:
    now = time.time()
    cached = _signed_cache.get(url)
    if cached and now < cached[0]:
        return cached[1]
    signed = await _supabase_sign_url(url, expires_sec=link_ttl_sec)
    if signed:
        _signed_cache[url] = (now + cache_ttl, signed)
    return signed


# --------- Config ----------
POINTS_WINDOW_MIN    = int(os.getenv("POINTS_WINDOW_MIN", "240"))
MAX_REPORTS          = int(os.getenv("MAX_REPORTS", "500"))
RESTORE_RADIUS_M     = int(os.getenv("RESTORE_RADIUS_M", "200"))
CLEANUP_RADIUS_M     = int(os.getenv("CLEANUP_RADIUS_M", "80"))
OWNERSHIP_RADIUS_M   = int(os.getenv("OWNERSHIP_RADIUS_M", "150"))
OWNERSHIP_WINDOW_MIN = int(os.getenv("OWNERSHIP_WINDOW_MIN", "1440"))  # 24h
ADMIN_TOKEN          = (os.getenv("ADMIN_TOKEN") or os.getenv("NEXT_PUBLIC_ADMIN_TOKEN") or "").strip()

# Pi√®ces jointes + auto-expire
ATTACH_WINDOW_H      = int(os.getenv("ATTACH_WINDOW_H", "48"))  # photos visibles pr√®s d‚Äôun incident sur 48h
AUTO_EXPIRE_H        = int(os.getenv("AUTO_EXPIRE_H", "6"))     # auto-cl√¥ture √† 6h

SUPABASE_URL         = (os.getenv("SUPABASE_URL") or "").rstrip("/")
SUPABASE_KEY         = os.getenv("SUPABASE_SERVICE_ROLE", "")
SUPABASE_BUCKET      = os.getenv("SUPABASE_BUCKET", "attachments")

ALERT_RADIUS_M   = int(os.getenv("ALERT_RADIUS_M", "100"))   # rayon des zones d'alerte (‚âà100m)
ALERT_WINDOW_H   = int(os.getenv("ALERT_WINDOW_H", "3"))     # fen√™tre de temps pour les preuves (3h)
ALERT_THRESHOLD  = int(os.getenv("ALERT_THRESHOLD", "3"))    # nb min de signalements pour une zone
RESPONDER_TOKEN  = (os.getenv("RESPONDER_TOKEN") or "").strip()  # jeton simple pour ‚Äúpompiers‚Äù

ALLOWED_KINDS = {
    # üîπ Propret√© RATP
    "urine", "vomit", "feces", "blood", "syringe", "broken_glass",
    # üîπ Anciens types Ayii (au cas o√π le front les appelle encore)
    "traffic", "accident", "fire", "flood", "power", "water",
    "assault", "weapon", "medical",
}

# --------- Helpers ----------
def _to_uuid_or_none(val: Optional[str]):
    try:
        if not val:
            return None
        return str(uuid.UUID(str(val)))
    except Exception:
        return None

def _check_admin_token(request: Request):
    if ADMIN_TOKEN:
        tok = request.headers.get("x-admin-token", "")
        if tok != ADMIN_TOKEN:
            raise HTTPException(status_code=401, detail="Invalid admin token")

def _now_isoz():
    return datetime.now(timezone.utc).isoformat().replace("+00:00", "Z")

# --------- Preflight CORS ----------
@router.options("/report")
async def options_report():
    resp = Response(status_code=204)
    resp.headers["Access-Control-Allow-Origin"] = "*"
    resp.headers["Access-Control-Allow-Methods"] = "POST, OPTIONS"
    resp.headers["Access-Control-Allow-Headers"] = "Content-Type, x-admin-token"
    resp.headers["Vary"] = "Origin"
    return resp

@router.options("/upload_image")
async def options_upload_image():
    resp = Response(status_code=204)
    resp.headers["Access-Control-Allow-Origin"] = "*"
    resp.headers["Access-Control-Allow-Methods"] = "POST, OPTIONS"
    resp.headers["Access-Control-Allow-Headers"] = "Content-Type, x-admin-token"
    resp.headers["Vary"] = "Origin"
    return resp

# === UPLOAD VIDEO (s√©par√© de l‚Äôupload d‚Äôimage) ============================
@router.post("/upload_video")
async def upload_video(
    kind: str = Form(...),
    lat: float = Form(...),
    lng: float = Form(...),
    user_id: Optional[UUID] = Form(None),
    idempotency_key: Optional[str] = Form(None),
    file: UploadFile = File(...),
    request: Request = None,
    db: AsyncSession = Depends(get_db),
):
    """
    Upload d'une vid√©o pour un incident de propret√© RATP.
    - v√©rifie que l'utilisateur est bien l'auteur (sauf admin)
    - stocke sur Supabase (ou fallback disque)
    - ins√®re dans attachments
    """
    import os, uuid, time as _time
    from sqlalchemy import text
    from app.config import BASE_PUBLIC_URL, STATIC_DIR, STATIC_URL_PATH

    # ‚úÖ normalisation du kind (TR√àS IMPORTANT)
    K = (kind or "").strip().lower()
    # pour la version propret√© RATP, on accepte les 6 types suivants :
    allowed_kinds = {"urine", "vomit", "feces", "blood", "syringe", "broken_glass"}
    if K not in allowed_kinds:
        raise HTTPException(status_code=400, detail="invalid kind")

    # admin ?
    is_admin = False
    try:
        admin_hdr = (request.headers.get("x-admin-token") or "").strip()
        admin_tok = (os.getenv("ADMIN_TOKEN") or os.getenv("NEXT_PUBLIC_ADMIN_TOKEN") or "").strip()
        is_admin = bool(admin_tok) and admin_hdr == admin_tok
    except Exception:
        pass

    # lire le fichier
    data = await file.read()
    if not data:
        raise HTTPException(status_code=400, detail="empty file")

    # ‚úÖ limite √† 15 MB
    if len(data) > 15 * 1024 * 1024:
        raise HTTPException(status_code=400, detail="video too large (max ~15MB)")

    # idem key
    idem = (idempotency_key or "").strip() or None
    if idem:
        rs = await db.execute(
            text("SELECT id, url FROM attachments WHERE idempotency_key = :k LIMIT 1"),
            {"k": idem},
        )
        row = rs.first()
        if row:
            return {
                "ok": True,
                "id": str(row.id),
                "url": row.url,
                "idempotency_key": idem,
            }

    # si pas admin ‚Üí v√©rifier qu'il a bien d√©clar√© √† cet endroit r√©cemment
    if not is_admin:
        if not user_id:
            raise HTTPException(status_code=403, detail="not_owner")
        chk = await db.execute(
            text("""
                WITH me AS (
                    SELECT ST_SetSRID(ST_MakePoint(:lng,:lat),4326)::geography AS g
                )
                SELECT 1
                  FROM reports
                 WHERE user_id = :uid
                   AND LOWER(TRIM(kind::text)) = :k
                   AND LOWER(TRIM(signal::text)) = 'to_clean'
                   AND created_at > NOW() - INTERVAL '48 hour'
                   AND ST_DWithin(geom::geography, (SELECT g FROM me), 150)
                 LIMIT 1
            """),
            {
                "uid": str(user_id),
                "k": K,
                "lat": float(lat),
                "lng": float(lng),
            },
        )
        if chk.first() is None:
            raise HTTPException(status_code=403, detail="not_owner")

    # d√©terminer l'extension √† partir du content-type
    ctype = (file.content_type or "").lower().strip()
    if ctype.startswith("video/webm"):
        ext = ".webm"
    elif ctype.startswith("video/3gpp") or ctype.startswith("video/3gp"):
        ext = ".3gp"
    else:
        ext = ".mp4"  # d√©faut

    filename_orig = file.filename or f"{K}_{uuid.uuid4().hex}{ext}"
    if "." not in filename_orig:
        filename_orig = filename_orig + ext

    # chemin dans le bucket ‚Üí IMPORTANT : on utilise K ici
    path = f"{K}/{int(_time.time())}-{uuid.uuid4().hex}-{os.path.basename(filename_orig)}"

    # upload
    url_public: Optional[str] = None
    try:
        bucket   = os.getenv("SUPABASE_BUCKET", "attachments")
        supa_url = (os.getenv("SUPABASE_URL") or "").rstrip("/")
        supa_key = os.getenv("SUPABASE_SERVICE_ROLE") or os.getenv("SUPABASE_SERVICE_KEY")

        if supa_url and supa_key:
            import httpx
            upload_url = f"{supa_url}/storage/v1/object/{bucket}/{path}"
            headers = {
                "Authorization": f"Bearer {supa_key}",
                "Content-Type": ctype or "video/mp4",
                "x-upsert": "false",
            }
            async with httpx.AsyncClient(timeout=60) as client:
                r = await client.post(upload_url, headers=headers, content=data)
            if r.status_code not in (200, 201):
                raise RuntimeError(f"supabase upload failed [{r.status_code}]: {r.text}")
            url_public = f"{supa_url}/storage/v1/object/public/{bucket}/{path}"
        else:
            # fallback disque
            raise RuntimeError("supabase credentials missing")
    except Exception:
        # fallback disque
        os.makedirs(STATIC_DIR, exist_ok=True)
        disk_name = os.path.basename(path)
        disk_path = os.path.join(STATIC_DIR, disk_name)
        with open(disk_path, "wb") as fp:
            fp.write(data)
        base = (BASE_PUBLIC_URL or "").rstrip("/")
        if base:
            url_public = f"{base}{STATIC_URL_PATH}/{disk_name}"
        else:
            url_public = f"{STATIC_URL_PATH}/{disk_name}"

    if not url_public:
        raise HTTPException(status_code=500, detail="no_public_url")

        # ins√©rer dans attachments
        # ins√©rer dans attachments (version RATP simplifi√©e)
    ins = text("""
        INSERT INTO attachments (
            kind, geom, user_id, url, idempotency_key, created_at
        )
        VALUES (
            :k,
            ST_SetSRID(ST_MakePoint(:lng,:lat),4326)::geography,
            :uid,
            :url,
            :idem,
            NOW()
        )
        RETURNING id
    """)
    rs = await db.execute(
        ins,
        {
            "k": K,
            "lng": float(lng),
            "lat": float(lat),
            "uid": str(user_id) if user_id else None,
            "url": url_public,
            "idem": idem,
        },
    )
    row = rs.first()
    await db.commit()

    return {
        "ok": True,
        "id": str(row.id),
        "url": url_public,
        "idempotency_key": idem,
    }



@router.post("/maintenance/purge_old_attachments")
async def purge_old_attachments(
    request: Request,
    db: AsyncSession = Depends(get_db),
):
    """
    Supprime de la base les attachments plus vieux que 49 jours.
    (√† appeler via cron ou √† la main)
    """
    import os
    from sqlalchemy import text

    admin_tok = (os.getenv("ADMIN_TOKEN") or "").strip()
    req_tok = (request.headers.get("x-admin-token") or "").strip()
    if not admin_tok or req_tok != admin_tok:
      raise HTTPException(status_code=403, detail="forbidden")

    # on r√©cup√®re les vieux (pour info)
    rs = await db.execute(
        text("""
            SELECT id, url
            FROM attachments
            WHERE created_at < NOW() - INTERVAL '49 days'
        """)
    )
    rows = rs.mappings().all()

    # on supprime en base
    await db.execute(
        text("DELETE FROM attachments WHERE created_at < NOW() - INTERVAL '49 days'")
    )
    await db.commit()

    return {"ok": True, "deleted": len(rows)}



# --------- Upload vers Supabase Storage ----------
async def _upload_to_supabase(file_bytes: bytes, filename: str, content_type: str) -> str:
    SUPA_URL = (os.getenv("SUPABASE_URL") or "").rstrip("/")
    SUPA_KEY = os.getenv("SUPABASE_SERVICE_ROLE", "")
    BUCKET   = os.getenv("SUPABASE_BUCKET", "attachments")

    if not (SUPA_URL and SUPA_KEY and BUCKET):
        raise HTTPException(status_code=500, detail="supabase creds missing (SUPABASE_URL / SUPABASE_SERVICE_ROLE / SUPABASE_BUCKET)")

    import httpx, time as _time, uuid as _uuid
    path = f"{int(_time.time())}/{_uuid.uuid4()}-{(filename or 'photo.jpg')}"
    upload_url = f"{SUPA_URL}/storage/v1/object/{BUCKET}/{path}"
    headers = {
        "Authorization": f"Bearer {SUPA_KEY}",
        "Content-Type": content_type or "application/octet-stream",
        "x-upsert": "true",
    }

    try:
        async with httpx.AsyncClient(timeout=30) as client:
            r = await client.post(upload_url, headers=headers, content=file_bytes)
    except httpx.ConnectError as e:
        raise HTTPException(502, detail=f"supabase connect error: {e}")
    except httpx.ReadTimeout as e:
        raise HTTPException(504, detail=f"supabase timeout: {e}")
    except Exception as e:
        raise HTTPException(500, detail=f"supabase http error: {e}")

    if r.status_code not in (200, 201):
        raise HTTPException(status_code=500, detail=f"supabase upload failed [{r.status_code}]: {r.text}")

    return f"{SUPA_URL}/storage/v1/object/public/{BUCKET}/{path}"

# ---------- LECTURES (outages/incidents) ----------
async def fetch_outages(db: AsyncSession, lat: float, lng: float, r_m: float):
    q_full = text(f"""
        WITH me AS (
          SELECT ST_SetSRID(ST_MakePoint(:lng,:lat),4326)::geography AS g
        )
        SELECT o.id,
               o.kind::text AS kind,
               CASE WHEN o.restored_at IS NULL THEN 'active' ELSE 'restored' END AS status,
               ST_Y((o.center::geometry)) AS lat,
               ST_X((o.center::geometry)) AS lng,
               o.started_at AS created_at,
               o.started_at,
               o.restored_at,
               COALESCE(att.cnt, 0)::int AS attachments_count,
               COALESCE(rep.cnt, 0)::int AS reports_count
        FROM outages o
        LEFT JOIN LATERAL (
          SELECT COUNT(*)::int AS cnt
            FROM attachments a
           WHERE a.kind::text = o.kind::text
             AND a.created_at > NOW() - INTERVAL '48 hours'
             AND ST_DWithin((a.geom::geography), (o.center::geography), 120)
        ) att ON TRUE
        LEFT JOIN LATERAL (
          SELECT COUNT(*)::int AS cnt
            FROM reports r
           WHERE LOWER(TRIM(r.signal::text))='cut'
             AND r.created_at > NOW() - INTERVAL '{POINTS_WINDOW_MIN} minutes'
             AND r.kind::text = o.kind::text
             AND ST_DWithin((r.geom::geography), (o.center::geography), 120)
        ) rep ON TRUE
        WHERE ST_DWithin((o.center::geography), (SELECT g FROM me), :r)
        ORDER BY o.started_at DESC NULLS LAST, o.id DESC
    """)
    q_min = text(f"""
        WITH me AS (
          SELECT ST_SetSRID(ST_MakePoint(:lng,:lat),4326)::geography AS g
        )
        SELECT o.id,
               o.kind::text AS kind,
               CASE WHEN o.restored_at IS NULL THEN 'active' ELSE 'restored' END AS status,
               ST_Y((o.center::geometry)) AS lat,
               ST_X((o.center::geometry)) AS lng,
               o.started_at AS created_at,
               o.started_at,
               o.restored_at,
               0::int AS attachments_count,
               0::int AS reports_count
        FROM outages o
        WHERE ST_DWithin((o.center::geography), (SELECT g FROM me), :r)
        ORDER BY o.started_at DESC NULLS LAST, o.id DESC
    """)
    try:
        res = await db.execute(q_full, {"lng": lng, "lat": lat, "r": r_m})
    except Exception:
        await db.rollback()
        res = await db.execute(q_min, {"lng": lng, "lat": lat, "r": r_m})
    rows = res.fetchall()
    return [
        {
            "id": r.id, "kind": r.kind, "status": r.status,
            "lat": float(r.lat), "lng": float(r.lng),
            "created_at": getattr(r, "created_at", None),
            "started_at": getattr(r, "started_at", None),
            "restored_at": getattr(r, "restored_at", None),
            "attachments_count": getattr(r, "attachments_count", 0),
            "reports_count": getattr(r, "reports_count", 0),
        } for r in rows
    ]


async def fetch_outages_all(db: AsyncSession, limit: int = 2000):
    q = text(f"""
        SELECT o.id,
               o.kind::text AS kind,
               CASE WHEN o.restored_at IS NULL THEN 'active' ELSE 'restored' END AS status,
               ST_Y((o.center::geometry)) AS lat,
               ST_X((o.center::geometry)) AS lng,
               COALESCE(o.created_at, o.started_at) AS created_at,
               o.started_at,
               o.restored_at,
               COALESCE(att.cnt, 0)::int AS attachments_count,
               COALESCE(rep.cnt, 0)::int AS reports_count
        FROM outages o
        LEFT JOIN LATERAL (
          SELECT COUNT(*)::int AS cnt
            FROM attachments a
           WHERE a.kind::text = o.kind::text
             AND a.created_at > NOW() - INTERVAL '48 hours'
             AND ST_DWithin((a.geom::geography), (o.center::geography), 120)
        ) att ON TRUE
        LEFT JOIN LATERAL (
          SELECT COUNT(*)::int AS cnt
            FROM reports r
           WHERE LOWER(TRIM(r.signal::text))='cut'
             AND r.created_at > NOW() - INTERVAL '{POINTS_WINDOW_MIN} minutes'
             AND r.kind::text = o.kind::text
             AND ST_DWithin((r.geom::geography), (o.center::geography), 120)
        ) rep ON TRUE
        WHERE o.restored_at IS NULL
        ORDER BY o.started_at DESC NULLS LAST, o.id DESC
        LIMIT :lim
    """)
    res = await db.execute(q, {"lim": limit})
    rows = res.fetchall()
    return [
        {
            "id": r.id, "kind": r.kind, "status": r.status,
            "lat": float(r.lat), "lng": float(r.lng),
            "created_at": getattr(r, "created_at", None),
            "started_at": getattr(r, "started_at", None),
            "restored_at": getattr(r, "restored_at", None),
            "attachments_count": getattr(r, "attachments_count", 0),
            "reports_count": getattr(r, "reports_count", 0),
        } for r in rows
    ]

async def fetch_incidents(db: AsyncSession, lat: float, lng: float, r_m: float):
    """
    Version RATP : on lit directement les reports 'to_clean' comme des incidents.
    Chaque report = 1 'incident' sur la carte.
    """
    q = text("""
        WITH me AS (
          SELECT ST_SetSRID(ST_MakePoint(:lng,:lat),4326)::geography AS g
        )
        SELECT
            r.id,
            r.kind::text AS kind,
            'active' AS status,
            ST_Y((r.geom::geometry)) AS lat,
            ST_X((r.geom::geometry)) AS lng,
            r.created_at AS created_at,
            r.created_at AS started_at,
            NULL::timestamp AS restored_at,
            COALESCE(att.cnt, 0)::int AS attachments_count,
            1::int AS reports_count,
            r.note::text AS note_text
        FROM reports r
        LEFT JOIN LATERAL (
          SELECT COUNT(*)::int AS cnt
            FROM attachments a
           WHERE a.kind::text = r.kind::text
             AND a.created_at > NOW() - INTERVAL '48 hours'
             AND ST_DWithin((a.geom::geography), (r.geom::geography), 120)
        ) att ON TRUE
        WHERE LOWER(TRIM(r.signal::text)) = 'to_clean'
          AND ST_DWithin((r.geom::geography), (SELECT g FROM me), :r)
        ORDER BY r.created_at DESC, r.id DESC
        LIMIT :lim
    """)

    res = await db.execute(q, {"lng": lng, "lat": lat, "r": r_m, "lim": MAX_REPORTS})
    rows = res.fetchall()

    return [
        {
            "id": r.id,
            "kind": r.kind,
            "status": r.status,
            "lat": float(r.lat),
            "lng": float(r.lng),
            "created_at": getattr(r, "created_at", None),
            "started_at": getattr(r, "started_at", None),
            "restored_at": getattr(r, "restored_at", None),
            "attachments_count": getattr(r, "attachments_count", 0),
            "reports_count": getattr(r, "reports_count", 0),
            "note": getattr(r, "note_text", None),
        }
        for r in rows
    ]


async def fetch_incidents_all(db: AsyncSession, limit: int = 2000):
    """
    Version globale : tous les reports 'to_clean' r√©cents sont consid√©r√©s comme incidents.
    Utilis√© si show_all=true.
    """
    q = text("""
        SELECT
            r.id,
            r.kind::text AS kind,
            'active' AS status,
            ST_Y((r.geom::geometry)) AS lat,
            ST_X((r.geom::geometry)) AS lng,
            r.created_at AS created_at,
            r.created_at AS started_at,
            NULL::timestamp AS restored_at,
            COALESCE(att.cnt, 0)::int AS attachments_count,
            1::int AS reports_count,
            r.note::text AS note_text
        FROM reports r
        LEFT JOIN LATERAL (
          SELECT COUNT(*)::int AS cnt
            FROM attachments a
           WHERE a.kind::text = r.kind::text
             AND a.created_at > NOW() - INTERVAL '48 hours'
             AND ST_DWithin((a.geom::geography), (r.geom::geography), 120)
        ) att ON TRUE
        WHERE LOWER(TRIM(r.signal::text)) = 'to_clean'
        ORDER BY r.created_at DESC, r.id DESC
        LIMIT :lim
    """)

    res = await db.execute(
        q,
        {"lim": min(limit, MAX_REPORTS)},
    )
    rows = res.fetchall()

    return [
        {
            "id": r.id,
            "kind": r.kind,
            "status": r.status,
            "lat": float(r.lat),
            "lng": float(r.lng),
            "created_at": getattr(r, "created_at", None),
            "started_at": getattr(r, "started_at", None),
            "restored_at": getattr(r, "restored_at", None),
            "attachments_count": getattr(r, "attachments_count", 0),
            "reports_count": getattr(r, "reports_count", 0),
            "note": getattr(r, "note_text", None),
        }
        for r in rows
    ]



# --- Helper pour /map : zones d‚Äôalerte via cluster DBSCAN ---

# --- Helper pour /map : zones d‚Äôalerte via cluster DBSCAN ---
async def fetch_alert_zones(db: AsyncSession, lat: float, lng: float, r_m: float):
    """
    Regroupe les reports 'cut' r√©cents par proximit√© (DBSCAN-like)
    et renvoie des clusters {kind, count, lat, lng} pr√™ts pour la carte.
    Compatible avec tous les types (incidents + outages).
    """
    window_min = int(ALERT_WINDOW_H) * 60  # passer heures -> minutes
    group_radius_m = float(ALERT_RADIUS_M)
    threshold = int(ALERT_THRESHOLD)

    sql = text(f"""
        WITH me AS (
          SELECT ST_SetSRID(ST_MakePoint(:lng,:lat),4326)::geography AS g
        ),
        pts AS (
          SELECT
            id,
            kind::text AS kind,
            ST_SnapToGrid(ST_Transform((geom::geometry),3857), 1.0) AS g3857,
            (geom::geometry) AS g4326
          FROM reports
          WHERE created_at > NOW() - INTERVAL '{window_min} minutes'
            AND LOWER(TRIM(signal::text))='cut'
            AND ST_DWithin((geom::geography), (SELECT g FROM me), :r)
            AND kind IN ('traffic','accident','fire','flood','power','water','assault','weapon','medical')
        ),
        clus AS (
          SELECT
            kind,
            ST_ClusterDBSCAN(g3857, eps := :eps, minpoints := 2) OVER () AS cid,
            g4326
          FROM pts
        ),
        agg AS (
          SELECT
            kind,
            cid,
            COUNT(*)::int AS n,
            ST_Transform(ST_Centroid(ST_Collect(g4326)), 4326) AS center4326
          FROM clus
          WHERE cid IS NOT NULL
          GROUP BY kind, cid
        ),
        zones AS (
          SELECT
            a.kind,
            a.n,
            ST_Y(a.center4326) AS lat,
            ST_X(a.center4326) AS lng
          FROM agg a
          WHERE a.n >= :threshold
        )
        SELECT z.kind, z.n, z.lat, z.lng
        FROM zones z
        WHERE NOT EXISTS (
          SELECT 1
          FROM acks ak
          WHERE ak.kind = z.kind
            AND ST_DWithin(
              (ST_SetSRID(ST_MakePoint(z.lng, z.lat),4326)::geography),
              ak.geom,
              :ack_r
            )
        )
        ORDER BY z.kind, z.n DESC
    """)

    params = {
        "lat": float(lat),
        "lng": float(lng),
        "r": float(r_m),
        "eps": group_radius_m,
        "threshold": threshold,
        "ack_r": group_radius_m,
    }

    try:
        res = await db.execute(sql, params)
        rows = res.fetchall()
    except Exception as e:
        await db.rollback()
        print(f"‚ö†Ô∏è fetch_alert_zones SQL error: {e}")
        return []

    return [
        {"kind": r.kind, "count": int(r.n), "lat": float(r.lat), "lng": float(r.lng)}
        for r in rows
    ]



# ---------- ENDPOINT /map ----------
from datetime import datetime  # en haut du fichier si pas d√©j√† import√©

@router.get("/map")
async def map_view(
    lat: float = Query(0.0, ge=-90, le=90),
    lng: float = Query(0.0, ge=-180, le=180),
    radius_km: float = Query(5.0, gt=0, le=50),
    show_all: bool = Query(
        False,
        description="Si true: renvoie tous les √©v√©nements actifs (cap).",
    ),
    db: AsyncSession = Depends(get_db),
):
    """
    Vue carte RATP : renvoie outages + incidents + last_reports
    """

    # rayon s√©curis√©
    r_km = max(0.3, min(radius_km, 50.0))
    r_m = float(r_km * 1000.0)

    # ‚úÖ toujours initialis√©s pour √©viter UnboundLocalError
    outages = []
    incidents = []
    last_reports = []
    alert_zones = []

    try:
        # 0) Auto-cl√¥ture incidents/outages anciens (si activ√©)
        try:
            if os.getenv("AUTO_EXPIRE_ENABLED", "1") != "0":
                await db.execute(text(f"""
                    UPDATE incidents
                       SET restored_at = COALESCE(restored_at, NOW())
                     WHERE restored_at IS NULL
                       AND started_at  < NOW() - INTERVAL '{AUTO_EXPIRE_H} hours'
                """))
                await db.execute(text(f"""
                    UPDATE outages
                       SET restored_at = COALESCE(restored_at, NOW())
                     WHERE restored_at IS NULL
                       AND started_at  < NOW() - INTERVAL '{AUTO_EXPIRE_H} hours'
                """))
                await db.commit()
        except Exception:
            await db.rollback()

        # 1) lecture globale ou locale
        if show_all:
            outages = await fetch_outages_all(db, limit=2000)
            incidents = await fetch_incidents_all(db, limit=2000)
            # alert_zones reste [] en mode global
        else:
            outages = await fetch_outages(db, lat, lng, r_m)
            incidents = await fetch_incidents(db, lat, lng, r_m)
            # si tu veux remettre les vraies alert_zones plus tard :
            # alert_zones = await fetch_alert_zones(db, lat, lng, r_m)

            # ici on pourrait aussi remplir last_reports si besoin
            # pour l‚Äôinstant on laisse [] pour simplifier

        # üîß created_at = started_at si manquant (pour le "Signal√© il y a ...")
        for inc in incidents:
            if not inc.get("created_at"):
                inc["created_at"] = inc.get("started_at")

        return {
            "outages": outages,
            "incidents": incidents,
            "alert_zones": alert_zones,
            "last_reports": last_reports,
            "server_now": datetime.utcnow().isoformat() + "Z",
        }

    except Exception as e:
        try:
            await db.rollback()
        except Exception:
            pass

        return {
            "outages": outages,
            "incidents": incidents,
            "alert_zones": alert_zones,
            "last_reports": last_reports,
            "server_now": datetime.utcnow().isoformat() + "Z",
            "error": f"{type(e).__name__}: {e}",
        }



@router.get("/reports_recent")
async def reports_recent(
    request: Request,
    db: AsyncSession = Depends(get_db),
):
    import os
    from sqlalchemy import text

    admin_tok = (os.getenv("ADMIN_TOKEN") or "").strip()
    req_tok = (request.headers.get("x-admin-token") or "").strip()
    if not admin_tok or req_tok != admin_tok:
        raise HTTPException(status_code=403, detail="forbidden")

    rs = await db.execute(text("""
        SELECT id, kind, signal, ST_Y(geom::geometry) AS lat, ST_X(geom::geometry) AS lng,
               user_id, created_at, phone
        FROM reports
        ORDER BY created_at DESC
        LIMIT 100
    """))
    rows = rs.mappings().all()
    return [dict(r) for r in rows]


# --------- Admin: factory reset ----------
@router.post("/admin/factory_reset")
async def admin_factory_reset(request: Request, db: AsyncSession = Depends(get_db)):
    _check_admin_token(request)
    try:
        for ddl in [
            "TRUNCATE TABLE reports RESTART IDENTITY CASCADE",
            "TRUNCATE TABLE incidents RESTART IDENTITY CASCADE",
            "TRUNCATE TABLE outages RESTART IDENTITY CASCADE",
            "TRUNCATE TABLE attachments RESTART IDENTITY CASCADE"
        ]:
            try:
                await db.execute(text(ddl))
            except Exception:
                await db.rollback()

        await db.commit()

        try:
            await db.execute(text("ALTER TABLE incidents ADD COLUMN IF NOT EXISTS restored_at timestamp NULL"))
            await db.execute(text("ALTER TABLE outages   ADD COLUMN IF NOT EXISTS restored_at timestamp NULL"))
            await db.execute(text("CREATE INDEX IF NOT EXISTS idx_incidents_center ON incidents USING GIST ((center::geometry))"))
            await db.execute(text("CREATE INDEX IF NOT EXISTS idx_outages_center   ON outages   USING GIST ((center::geometry))"))
            await db.execute(text("CREATE INDEX IF NOT EXISTS idx_incidents_kind ON incidents(kind)"))
            await db.execute(text("CREATE INDEX IF NOT EXISTS idx_outages_kind   ON outages(kind)"))
            await db.commit()
        except Exception:
            await db.rollback()

        return {"ok": True}
    except Exception as e:
        await db.rollback()
        raise HTTPException(status_code=500, detail=f"factory_reset failed: {e}")

# --------- Upload image ----------
@router.post("/upload_image")
async def upload_image(
    kind: str = Form(...),
    lat: float = Form(...),
    lng: float = Form(...),
    user_id: Optional[UUID] = Form(None),
    idempotency_key: Optional[str] = Form(None),
    file: UploadFile = File(...),
    request: Request = None,
    db: AsyncSession = Depends(get_db),
):
    # --- Admin simple (header x-admin-token)
    is_admin = False
    try:
        admin_hdr = (request.headers.get("x-admin-token") or "").strip()
        if admin_hdr and admin_hdr == (os.getenv("ADMIN_TOKEN") or os.getenv("NEXT_PUBLIC_ADMIN_TOKEN") or ""):
            is_admin = True
    except Exception:
        pass

    K = (kind or "").strip().lower()
    if K not in ALLOWED_KINDS:
         raise HTTPException(status_code=400, detail="invalid kind")


    # --- lecture du fichier
    data = await file.read()
    if not data:
        raise HTTPException(status_code=400, detail="empty file")

    ctype = (file.content_type or "").lower().strip()
    is_image = ctype.startswith("image/")
    is_video = ctype.startswith("video/")

    if not (is_image or is_video):
        # accepte uniquement image/* ou video/* (webm/mp4)
        raise HTTPException(status_code=415, detail=f"unsupported content-type: {ctype or 'unknown'}")

    # bornes de taille : image 15Mo, vid√©o 50Mo
    if is_image and len(data) > 15 * 1024 * 1024:
        raise HTTPException(status_code=413, detail="image too large")
    if is_video and len(data) > 50 * 1024 * 1024:
        raise HTTPException(status_code=413, detail="video too large")

    # --- idempotency
    idem = (idempotency_key or "").strip() or None
    if idem:
        q = text("SELECT id, url FROM attachments WHERE idempotency_key = :k LIMIT 1")
        rs = await db.execute(q, {"k": idem})
        row = rs.first()
        if row:
            return {
                "ok": True,
                "id": str(row.id),
                "url": row.url if is_admin else None,  # ne montre l'URL qu'√† l‚Äôadmin
                "idempotency_key": idem,
            }

    # --- Ownership check : si pas admin, l'uploader doit avoir un report r√©cent proche
    if not is_admin:
        if not user_id:
            raise HTTPException(status_code=403, detail="not_owner")
        chk = text("""
            WITH me AS (SELECT ST_SetSRID(ST_MakePoint(:lng,:lat),4326)::geography AS g)
            SELECT 1
              FROM reports
             WHERE user_id = :uid
               AND LOWER(TRIM(kind::text))   = :k
               AND LOWER(TRIM(signal::text)) = 'cut'
               AND created_at > NOW() - INTERVAL '48 hours'
               AND ST_DWithin((geom::geography),(SELECT g FROM me),150)
             LIMIT 1
        """)
        rs = await db.execute(chk, {"uid": str(user_id), "k": K, "lat": lat, "lng": lng})
        if rs.first() is None:
            raise HTTPException(status_code=403, detail="not_owner")

    # --- choix extension/filename
    ext = ".jpg"
    if is_video:
        if "mp4" in ctype:
            ext = ".mp4"
        elif "webm" in ctype:
            ext = ".webm"
        else:
            ext = ".mp4"
    else:
        if "jpeg" in ctype:
            ext = ".jpg"
        elif "png" in ctype:
            ext = ".png"
        elif "webp" in ctype:
            ext = ".webp"
        else:
            ext = ".jpg"

    # --- stockage Supabase (si configur√©) sinon local
    url_public = None
    bucket   = os.getenv("SUPABASE_BUCKET", "attachments")
    supa_url = (os.getenv("SUPABASE_URL") or "").rstrip("/")
    supa_key = os.getenv("SUPABASE_SERVICE_ROLE") or os.getenv("SUPABASE_SERVICE_KEY")

    try:
        if supa_url and supa_key:
            import httpx
            path = f"{K}/{int(time.time())}-{uuid.uuid4()}{ext}"
            upload_url = f"{supa_url}/storage/v1/object/{bucket}/{path}"
            headers = {
                "Authorization": f"Bearer {supa_key}",
                "Content-Type": ctype or ("video/mp4" if is_video else "image/jpeg"),
                "x-upsert": "false",
            }
            async with httpx.AsyncClient(timeout=30) as client:
                r = await client.post(upload_url, headers=headers, content=data)
            if r.status_code not in (200, 201):
                raise HTTPException(status_code=502, detail=f"supabase upload failed: {r.status_code}")
            url_public = f"{supa_url}/storage/v1/object/public/{bucket}/{path}"
        else:
            # local /static (dev)
            os.makedirs(STATIC_DIR, exist_ok=True)
            path = f"{K}-{uuid.uuid4()}{ext}"
            disk_path = os.path.join(STATIC_DIR, path)
            with open(disk_path, "wb") as fp:
                fp.write(data)
            base = (BASE_PUBLIC_URL or "").rstrip("/")
            url_public = f"{base}{STATIC_URL_PATH}/{path}" if base else f"{STATIC_URL_PATH}/{path}"
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"storage_error: {e}")

    if not url_public:
        raise HTTPException(status_code=500, detail="no_public_url")

    # --- insert DB
        # --- insert DB (version simplifi√©e pour sch√©ma RATP)
    ins = text("""
        INSERT INTO attachments (
            kind, geom, user_id, url, idempotency_key, created_at
        )
        VALUES (
            :k,
            ST_SetSRID(ST_MakePoint(:lng,:lat),4326)::geography,
            :uid,
            :url,
            :idem,
            NOW()
        )
        RETURNING id
    """)
    rs = await db.execute(
        ins,
        {
            "k": K,
            "lng": float(lng),
            "lat": float(lat),
            "uid": str(user_id) if user_id else None,
            "url": url_public,
            "idem": idem,
        },
    )
    new_id = rs.scalar() if hasattr(rs, "scalar") else (rs.first().id if rs.first() else None)
    await db.commit()

    return {
        "ok": True,
        "id": str(new_id) if new_id else None,
        "url": url_public if is_admin else None,
        "idempotency_key": idem,
    }






@router.get("/admin/supabase_status")
async def supabase_status():
    return {
        "SUPABASE_URL_set": bool(os.getenv("SUPABASE_URL")),
        "SUPABASE_SERVICE_ROLE_set": bool(os.getenv("SUPABASE_SERVICE_ROLE")),
        "SUPABASE_BUCKET": os.getenv("SUPABASE_BUCKET", "attachments"),
    }

# --------- RESET USER ----------
@router.post("/reset_user")
async def reset_user(id: str = Query(..., alias="id"), db: AsyncSession = Depends(get_db)):
    try:
        try:
            await db.execute(text("DELETE FROM reports WHERE user_id = :id"), {"id": id})
        except Exception:
            await db.execute(text("DELETE FROM reports WHERE user_id = :id::uuid"), {"id": id})
        await db.commit()
        return {"ok": True}
    except Exception as e:
        await db.rollback()
        raise HTTPException(status_code=500, detail=f"reset_user failed: {e}")

# --------- ADMIN maintenance ----------
@router.post("/admin/wipe_all")
async def admin_wipe_all(request: Request, truncate: bool = Query(False), db: AsyncSession = Depends(get_db)):
    _check_admin_token(request)
    try:
        if truncate:
            await db.execute(text("TRUNCATE TABLE reports RESTART IDENTITY CASCADE"))
            await db.execute(text("TRUNCATE TABLE incidents RESTART IDENTITY CASCADE"))
            await db.execute(text("TRUNCATE TABLE outages RESTART IDENTITY CASCADE"))
        else:
            await db.execute(text("DELETE FROM reports"))
            await db.execute(text("DELETE FROM incidents"))
            await db.execute(text("DELETE FROM outages"))
        await db.commit()
        return {"ok": True}
    except Exception as e:
        await db.rollback()
        raise HTTPException(status_code=500, detail=f"wipe_all failed: {e}")

@router.post("/admin/ensure_schema")
async def admin_ensure_schema(db: AsyncSession = Depends(get_db)):
    try:
        await db.execute(text("ALTER TABLE incidents ADD COLUMN IF NOT EXISTS restored_at timestamp NULL"))
        await db.execute(text("ALTER TABLE outages   ADD COLUMN IF NOT EXISTS restored_at timestamp NULL"))
        await db.execute(text("CREATE INDEX IF NOT EXISTS idx_incidents_center ON incidents USING GIST ((center::geometry))"))
        await db.execute(text("CREATE INDEX IF NOT EXISTS idx_outages_center   ON outages   USING GIST ((center::geometry))"))
        await db.execute(text("CREATE INDEX IF NOT EXISTS idx_incidents_kind ON incidents(kind)"))
        await db.execute(text("CREATE INDEX IF NOT EXISTS idx_outages_kind   ON outages(kind)"))
        await db.commit()
        return {"ok": True}
    except Exception as e:
        await db.rollback()
        raise HTTPException(status_code=500, detail=f"ensure_schema failed: {e}")

@router.post("/admin/normalize_reports")
async def admin_normalize_reports(db: AsyncSession = Depends(get_db)):
    try:
        await db.execute(text("UPDATE reports SET signal='cut' WHERE LOWER(TRIM(signal::text)) IN ('down','cut')"))
        await db.execute(text("UPDATE reports SET signal='restored' WHERE LOWER(TRIM(signal::text)) IN ('up','restored')"))
        await db.execute(text("DELETE FROM reports WHERE LOWER(TRIM(signal::text))='restored'"))
        await db.commit()
        return {"ok": True}
    except Exception as e:
        await db.rollback()
        raise HTTPException(status_code=500, detail=f"normalize_reports failed: {e}")

class AdminCreateIn(BaseModel):
    kind: str
    lat: float
    lng: float
    started_at: Optional[str] = None

class AdminNearIn(BaseModel):
    kind: str
    lat: float
    lng: float
    radius_m: int = RESTORE_RADIUS_M

@router.post("/admin/seed_incident")
async def admin_seed_incident(p: AdminCreateIn, db: AsyncSession = Depends(get_db)):
    try:
        await db.execute(
            text("""
                INSERT INTO incidents(kind, center, started_at, restored_at)
                VALUES (:kind, ST_SetSRID(ST_MakePoint(:lng,:lat),4326)::geography,
                        COALESCE(CAST(:started_at AS timestamp), NOW()), NULL)
            """),
            {"kind": p.kind, "lat": p.lat, "lng": p.lng, "started_at": p.started_at}
        )
        await db.commit()
        return {"ok": True}
    except Exception as e:
        await db.rollback()
        raise HTTPException(status_code=500, detail=f"seed_incident failed: {e}")

@router.post("/admin/seed_outage")
async def admin_seed_outage(p: AdminCreateIn, db: AsyncSession = Depends(get_db)):
    try:
        await db.execute(
            text("""
                INSERT INTO outages(kind, center, started_at, restored_at)
                VALUES (:kind, ST_SetSRID(ST_MakePoint(:lng,:lat),4326)::geography,
                        COALESCE(CAST(:started_at AS timestamp), NOW()), NULL)
            """),
            {"kind": p.kind, "lat": p.lat, "lng": p.lng, "started_at": p.started_at}
        )
        await db.commit()
        return {"ok": True}
    except Exception as e:
        await db.rollback()
        raise HTTPException(status_code=500, detail=f"seed_outage failed: {e}")

@router.post("/admin/restore_near")
async def admin_restore_near(p: AdminNearIn, db: AsyncSession = Depends(get_db)):
    try:
        table = "outages" if p.kind in ("power", "water") else "incidents"
        await db.execute(
            text(f"""
                WITH me AS (SELECT ST_SetSRID(ST_MakePoint(:lng,:lat),4326)::geography AS g)
                UPDATE {table} SET restored_at = NOW()
                WHERE kind = :kind AND ST_DWithin(center, (SELECT g FROM me), :r)
            """), {"kind": p.kind, "lat": p.lat, "lng": p.lng, "r": p.radius_m}
        )
        await db.commit()
        return {"ok": True}
    except Exception as e:
        await db.rollback()
        raise HTTPException(status_code=500, detail=f"restore_near failed: {e}")

@router.post("/admin/unrestore_near")
async def admin_unrestore_near(p: AdminNearIn, db: AsyncSession = Depends(get_db)):
    try:
        table = "outages" if p.kind in ("power", "water") else "incidents"
        await db.execute(
            text(f"""
                WITH me AS (SELECT ST_SetSRID(ST_MakePoint(:lng,:lat),4326)::geography AS g)
                UPDATE {table} SET restored_at = NULL
                WHERE kind = :kind AND ST_DWithin(center, (SELECT g FROM me), :r)
            """), {"kind": p.kind, "lat": p.lat, "lng": p.lng, "r": p.radius_m}
        )
        await db.commit()
        return {"ok": True}
    except Exception as e:
        await db.rollback()
        raise HTTPException(status_code=500, detail=f"unrestore_near failed: {e}")

@router.post("/admin/delete_near")
async def admin_delete_near(p: AdminNearIn, db: AsyncSession = Depends(get_db)):
    try:
        table = "outages" if p.kind in ("power", "water") else "incidents"
        await db.execute(
            text(f"""
                WITH me AS (SELECT ST_SetSRID(ST_MakePoint(:lng,:lat),4326)::geography AS g)
                DELETE FROM {table}
                WHERE kind = :kind AND ST_DWithin(center, (SELECT g FROM me), :r)
            """), {"kind": p.kind, "lat": p.lat, "lng": p.lng, "r": p.radius_m}
        )
        await db.commit()
        return {"ok": True}
    except Exception as e:
        await db.rollback()
        raise HTTPException(status_code=500, detail=f"delete_near failed: {e}")

@router.post("/admin/clear_restored_reports")
async def admin_clear_restored_reports(db: AsyncSession = Depends(get_db)):
    try:
        await db.execute(text("DELETE FROM reports WHERE LOWER(TRIM(signal::text))='restored'"))
        await db.commit()
        return {"ok": True}
    except Exception as e:
        await db.rollback()
        raise HTTPException(status_code=500, detail=f"clear_restored_reports failed: {e}")

@router.post("/admin/purge_old_reports")
async def admin_purge_old_reports(days: int = Query(7, ge=1, le=365), db: AsyncSession = Depends(get_db)):
    try:
        await db.execute(text("DELETE FROM reports WHERE created_at < NOW() - (:d || ' days')::interval"), {"d": days})
        await db.commit()
        return {"ok": True}
    except Exception as e:
        await db.rollback()
        raise HTTPException(status_code=500, detail=f"purge_old_reports failed: {e}")

@router.post("/admin/delete_report")
async def admin_delete_report(id: int = Query(...), db: AsyncSession = Depends(get_db)):
    try:
        await db.execute(text("DELETE FROM reports WHERE id = :id"), {"id": id})
        await db.commit()
        return {"ok": True}
    except Exception as e:
        await db.rollback()
        raise HTTPException(status_code=500, detail=f"delete_report failed: {e}")

# --- CSV exports ---
from fastapi.responses import StreamingResponse

def _is_admin_req(request: Request):
    # accepte soit l'en-t√™te, soit ?token=...
    hdr = request.headers.get("x-admin-token", "").strip()
    q = (request.query_params.get("token") or "").strip()
    tok = ADMIN_TOKEN
    return bool(tok) and (hdr == tok or q == tok)

def _parse_dt(s: str | None):
    if not s: return None
    s = s.strip()
    for fmt in ("%Y-%m-%d", "%Y-%m-%dT%H:%M", "%Y-%m-%dT%H:%M:%S"):
        try:
            return datetime.strptime(s, fmt)
        except Exception:
            pass
    return None

def _bbox_clause(min_lat, max_lat, min_lng, max_lng, alias="geom"):
    # alias = 'geom' (reports) ou 'center' (incidents/outages)
    parts = []
    params = {}
    try:
        if min_lat is not None: params["min_lat"] = float(min_lat)
        if max_lat is not None: params["max_lat"] = float(max_lat)
        if min_lng is not None: params["min_lng"] = float(min_lng)
        if max_lng is not None: params["max_lng"] = float(max_lng)
    except Exception:
        params = {}
    if len(params) == 4:
        parts.append(f"ST_Y({alias}::geometry) BETWEEN :min_lat AND :max_lat")
        parts.append(f"ST_X({alias}::geometry) BETWEEN :min_lng AND :max_lng")
    return (" AND ".join(parts), params)

@router.get("/admin/export_reports.csv")
async def admin_export_reports_csv(
    request: Request,
    date_from: str | None = None,
    date_to: str | None = None,
    kind: str | None = None,          # 'traffic'|'accident'|'fire'|'flood'|'power'|'water'
    signal: str | None = None,        # 'cut'|'restored'
    min_lat: float | None = None, max_lat: float | None = None,
    min_lng: float | None = None, max_lng: float | None = None,
    db: AsyncSession = Depends(get_db),
):
    if not _is_admin_req(request):
        raise HTTPException(status_code=401, detail="invalid admin token")

    dt_from = _parse_dt(date_from)
    dt_to   = _parse_dt(date_to)

    where = ["1=1"]
    params = {}
    if dt_from:
        where.append("created_at >= :df")
        params["df"] = dt_from
    if dt_to:
        where.append("created_at <= :dt")
        params["dt"] = dt_to
    if kind:
        where.append("kind = :kind")
        params["kind"] = kind
    if signal:
        where.append("LOWER(TRIM(signal::text)) = :sig")
        params["sig"] = signal.strip().lower()
    bbox_sql, bbox_params = _bbox_clause(min_lat, max_lat, min_lng, max_lng, alias="geom")
    if bbox_sql:
        where.append(bbox_sql)
        params.update(bbox_params)

    q = text(f"""
        SELECT id,
               kind::text AS kind,
               signal::text AS signal,
               ST_Y(geom::geometry) AS lat,
               ST_X(geom::geometry) AS lng,
               user_id,
               created_at
        FROM reports
        WHERE {" AND ".join(where)}
        ORDER BY created_at DESC, id DESC
        LIMIT 200000
    """)
    res = await db.execute(q, params)
    rows = res.fetchall()

    buf = io.StringIO()
    w = csv.writer(buf)
    w.writerow(["id","kind","signal","lat","lng","user_id","created_at"])
    for r in rows:
        w.writerow([r.id, r.kind, r.signal, float(r.lat), float(r.lng), r.user_id, r.created_at.isoformat() if r.created_at else ""])
    buf.seek(0)
    return StreamingResponse(buf, media_type="text/csv",
        headers={"Content-Disposition": "attachment; filename=reports.csv"})

@router.get("/admin/export_events.csv")
async def admin_export_events_csv(
    request: Request,
    date_from: str | None = None,
    date_to: str | None = None,
    kind: str | None = None,          # m√™me valeurs
    status: str | None = None,        # 'active'|'restored'
    table: str | None = None,         # 'incidents'|'outages'|'both' (par d√©faut both)
    min_lat: float | None = None, max_lat: float | None = None,
    min_lng: float | None = None, max_lng: float | None = None,
    db: AsyncSession = Depends(get_db),
):
    if not _is_admin_req(request):
        raise HTTPException(status_code=401, detail="invalid admin token")

    dt_from = _parse_dt(date_from)
    dt_to   = _parse_dt(date_to)

    def _build_sql(tab):
        where = ["1=1"]
        params = {}
        if dt_from:
            where.append("started_at >= :df")
            params["df"] = dt_from
        if dt_to:
            where.append("started_at <= :dt")
            params["dt"] = dt_to
        if kind:
            where.append("kind = :kind")
            params["kind"] = kind
        if status in ("active","restored"):
            if status == "active":
                where.append("restored_at IS NULL")
            else:
                where.append("restored_at IS NOT NULL")
        bbox_sql, bbox_params = _bbox_clause(min_lat, max_lat, min_lng, max_lng, alias="center")
        if bbox_sql:
            where.append(bbox_sql)
            params.update(bbox_params)
        sql = text(f"""
            SELECT '{tab}' AS table_name,
                   id,
                   kind::text AS kind,
                   CASE WHEN restored_at IS NULL THEN 'active' ELSE 'restored' END AS status,
                   ST_Y(center::geometry) AS lat,
                   ST_X(center::geometry) AS lng,
                   started_at,
                   restored_at
            FROM {tab}
            WHERE {" AND ".join(where)}
        """)
        return sql, params

    tabs = ["incidents","outages"] if table in (None,"both","") else [table]
    all_rows = []
    for tname in tabs:
        sql, par = _build_sql(tname)
        res = await db.execute(sql, par)
        all_rows.extend([("incidents" if tname=="incidents" else "outages",) + tuple(r) for r in res.fetchall()])  # not used directly

    # build CSV
    buf = io.StringIO()
    w = csv.writer(buf)
    w.writerow(["table","id","kind","status","lat","lng","started_at","restored_at","duration_min"])
    for tname in tabs:
        sql, par = _build_sql(tname)
        res = await db.execute(sql, par)
        for r in res.fetchall():
            started = r.started_at
            restored = r.restored_at
            dur_min = ""
            if started and restored:
                dur_min = int((restored - started).total_seconds() // 60)
            w.writerow([
                tname, r.id, r.kind, r.status,
                float(r.lat), float(r.lng),
                started.isoformat() if started else "",
                restored.isoformat() if restored else "",
                dur_min
            ])
    buf.seek(0)
    return StreamingResponse(buf, media_type="text/csv",
        headers={"Content-Disposition": "attachment; filename=events.csv"})

# --- GeoJSON exports ---
@router.get("/admin/export_reports.geojson")
async def admin_export_reports_geojson(
    request: Request,
    date_from: str | None = None,
    date_to: str | None = None,
    kind: str | None = None,          # 'traffic'|'accident'|'fire'|'flood'|'power'|'water'
    signal: str | None = None,        # 'cut'|'restored'
    min_lat: float | None = None, max_lat: float | None = None,
    min_lng: float | None = None, max_lng: float | None = None,
    limit: int = 200000,
    db: AsyncSession = Depends(get_db),
):
    if not _is_admin_req(request):
        raise HTTPException(status_code=401, detail="invalid admin token")

    dt_from = _parse_dt(date_from)
    dt_to   = _parse_dt(date_to)

    where = ["1=1"]
    params = {}
    if dt_from:
        where.append("created_at >= :df"); params["df"] = dt_from
    if dt_to:
        where.append("created_at <= :dt"); params["dt"] = dt_to
    if kind:
        where.append("kind = :kind"); params["kind"] = kind
    if signal:
        where.append("LOWER(TRIM(signal::text)) = :sig"); params["sig"] = signal.strip().lower()
    bbox_sql, bbox_params = _bbox_clause(min_lat, max_lat, min_lng, max_lng, alias="geom")
    if bbox_sql: where.append(bbox_sql); params.update(bbox_params)

    q = text(f"""
        SELECT
          id,
          kind::text AS kind,
          signal::text AS signal,
          ST_AsGeoJSON(geom::geometry)::text AS geom_json,
          user_id,
          created_at
        FROM reports
        WHERE {" AND ".join(where)}
        ORDER BY created_at DESC, id DESC
        LIMIT :lim
    """)
    params["lim"] = limit
    res = await db.execute(q, params)
    rows = res.fetchall()

    fc = {
        "type": "FeatureCollection",
        "features": []
    }
    for r in rows:
        try:
            geom = json.loads(r.geom_json)
        except Exception:
            continue
        fc["features"].append({
            "type": "Feature",
            "geometry": geom,
            "properties": {
                "id": r.id,
                "kind": r.kind,
                "signal": r.signal,
                "user_id": r.user_id,
                "created_at": r.created_at.isoformat() if r.created_at else None,
            }
        })
    buf = io.StringIO()
    json.dump(fc, buf, ensure_ascii=False)
    buf.seek(0)
    return StreamingResponse(buf, media_type="application/geo+json",
        headers={"Content-Disposition": "attachment; filename=reports.geojson"})

@router.get("/admin/export_events.geojson")
async def admin_export_events_geojson(
    request: Request,
    table: str | None = None,         # 'incidents'|'outages'|'both' (def both)
    date_from: str | None = None,
    date_to: str | None = None,
    kind: str | None = None,
    status: str | None = None,        # 'active'|'restored'
    min_lat: float | None = None, max_lat: float | None = None,
    min_lng: float | None = None, max_lng: float | None = None,
    limit: int = 200000,
    db: AsyncSession = Depends(get_db),
):
    if not _is_admin_req(request):
        raise HTTPException(status_code=401, detail="invalid admin token")

    dt_from = _parse_dt(date_from)
    dt_to   = _parse_dt(date_to)

    tabs = ["incidents","outages"] if table in (None,"both","") else [table]
    feats = []

    for tname in tabs:
        where = ["1=1"]
        params = {}
        if dt_from:
            where.append("started_at >= :df"); params["df"] = dt_from
        if dt_to:
            where.append("started_at <= :dt"); params["dt"] = dt_to
        if kind:
            where.append("kind = :kind"); params["kind"] = kind
        if status in ("active","restored"):
            if status == "active":
                where.append("restored_at IS NULL")
            else:
                where.append("restored_at IS NOT NULL")
        bbox_sql, bbox_params = _bbox_clause(min_lat, max_lat, min_lng, max_lng, alias="center")
        if bbox_sql: where.append(bbox_sql); params.update(bbox_params)

        sql = text(f"""
            SELECT
              id,
              kind::text AS kind,
              CASE WHEN restored_at IS NULL THEN 'active' ELSE 'restored' END AS status,
              ST_AsGeoJSON(center::geometry)::text AS geom_json,
              started_at, restored_at
            FROM {tname}
            WHERE {" AND ".join(where)}
            ORDER BY started_at DESC NULLS LAST, id DESC
            LIMIT :lim
        """)
        params["lim"] = limit
        res = await db.execute(sql, params)
        rows = res.fetchall()
        for r in rows:
            try:
                geom = json.loads(r.geom_json)
            except Exception:
                continue
            feats.append({
                "type": "Feature",
                "geometry": geom,
                "properties": {
                    "table": tname,
                    "id": r.id,
                    "kind": r.kind,
                    "status": r.status,
                    "started_at": r.started_at.isoformat() if r.started_at else None,
                    "restored_at": r.restored_at.isoformat() if r.restored_at else None,
                }
            })

    fc = {"type":"FeatureCollection","features":feats}
    buf = io.StringIO()
    json.dump(fc, buf, ensure_ascii=False)
    buf.seek(0)
    return StreamingResponse(buf, media_type="application/geo+json",
        headers={"Content-Disposition": "attachment; filename=events.geojson"})

# --- Attachments pr√®s d'un point ---

from typing import Optional
from uuid import UUID
import os
from fastapi import HTTPException, Query, Request, Depends
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import text

@router.get("/attachments_near")
async def attachments_near(
    kind: str = Query(...),
    lat: float = Query(..., ge=-90, le=90),
    lng: float = Query(..., ge=-180, le=180),
    radius_m: int = Query(150, ge=10, le=2000),
    hours: int = Query(48, ge=1, le=168),
    viewer_user_id: Optional[UUID] = Query(
        None,
        description="ID du user qui regarde (pour savoir si c'est lui qui a upload)"
    ),
    debug: int = Query(0),
    request: Request = None,
    db: AsyncSession = Depends(get_db),
):
    """
    Version stricte :
    - admin ‚Üí voit tout
    - celui qui a upload ‚Üí voit ses m√©dias
    - un autre qui d√©clare √† c√¥t√© ‚Üí ne voit pas
    - ?raw=1 ‚Üí redirection vers le 1er m√©dia autoris√©
    """
    import os
    from sqlalchemy import text
    from fastapi.responses import RedirectResponse

    k = (kind or "").strip().lower()
    if k not in ALLOWED_KINDS:
        raise HTTPException(status_code=400, detail="invalid kind")

    # admin ?
    is_admin = False
    try:
        admin_hdr = (request.headers.get("x-admin-token") or "").strip()
        admin_tok = (os.getenv("ADMIN_TOKEN") or "").strip()
        is_admin = bool(admin_tok) and admin_hdr == admin_tok
    except Exception:
        pass

    try:
        rs = await db.execute(
            text("""
                WITH me AS (
                    SELECT ST_SetSRID(ST_MakePoint(:lng,:lat),4326)::geography AS g
                )
                SELECT
                    id,
                    url,
                    ST_Y(geom::geometry) AS lat,
                    ST_X(geom::geometry) AS lng,
                    user_id,
                    created_at
                FROM attachments
                WHERE LOWER(TRIM(kind::text)) = :k
                  AND created_at > NOW() - (:hours * INTERVAL '1 hour')
                  AND ST_DWithin(geom::geography, (SELECT g FROM me), :r)
                ORDER BY created_at DESC, id DESC
                LIMIT 200
            """),
            {
                "k": k,
                "lng": lng,
                "lat": lat,
                "r": radius_m,
                "hours": int(hours),
            },
        )
        rows = rs.mappings().all()

        out = []
        for r in rows:
            uploader_id = str(r["user_id"]) if r["user_id"] else None
            raw_url = r["url"]

            # est-ce que ce viewer est bien l'uploader ?
            is_owner = False
            if viewer_user_id and uploader_id:
                if str(viewer_user_id) == uploader_id:
                    is_owner = True

            final_url = None
            guessed_mime = None

            if raw_url and (is_admin or is_owner):
                try:
                    final_url = await get_signed_cached(raw_url, cache_ttl=60, link_ttl_sec=300)
                except Exception:
                    if debug:
                        final_url = raw_url  # en debug on laisse brut
            else:
                final_url = None

            if final_url:
                low = final_url.lower()
                if low.endswith(".jpg") or low.endswith(".jpeg"):
                    guessed_mime = "image/jpeg"
                elif low.endswith(".png"):
                    guessed_mime = "image/png"
                elif low.endswith(".webp"):
                    guessed_mime = "image/webp"
                elif low.endswith(".mp4"):
                    guessed_mime = "video/mp4"
                elif low.endswith(".webm"):
                    guessed_mime = "video/webm"

            if final_url:
                out.append({
                    "id": str(r["id"]),
                    "kind": k,
                    "lat": float(r["lat"]),
                    "lng": float(r["lng"]),
                    "created_at": r["created_at"].isoformat() if r["created_at"] else None,
                    "url": final_url,
                    "mime_type": guessed_mime,
                    "uploader_id": uploader_id,
                })
            else:
                out.append({
                    "id": str(r["id"]),
                    "kind": k,
                    "lat": float(r["lat"]),
                    "lng": float(r["lng"]),
                    "created_at": r["created_at"].isoformat() if r["created_at"] else None,
                    "url": None,
                    "note": "üîí M√©dia r√©serv√© √† l'auteur ou √† l'admin",
                })

        # ?raw=1 ‚Üí on renvoie direct vers le 1er m√©dia autoris√©
        if request.query_params.get("raw") == "1":
            for item in out:
                if item.get("url"):
                    return RedirectResponse(item["url"])
            return out

        return out

    except Exception as e:
        if debug:
            raise HTTPException(status_code=500, detail=f"attachments_near error: {e}")
        raise HTTPException(status_code=500, detail="attachments_near error")




# --- Agr√©gations CSV (reports/events) ---
@router.get("/admin/export_aggregated.csv")
async def admin_export_aggregated_csv(
    request: Request,
    subject: str = "reports",         # 'reports' | 'events'
    by: str = "day_kind",             # 'day' | 'kind' | 'day_kind' | 'day_kind_status'
    table: str | None = None,         # pour events: 'incidents'|'outages'|'both'
    status: str | None = None,        # pour events: 'active'|'restored'
    date_from: str | None = None,
    date_to: str | None = None,
    kind: str | None = None,
    db: AsyncSession = Depends(get_db),
):
    if not _is_admin_req(request):
        raise HTTPException(status_code=401, detail="invalid admin token")

    dt_from = _parse_dt(date_from)
    dt_to   = _parse_dt(date_to)

    buf = io.StringIO()
    w = csv.writer(buf)

    if subject == "reports":
        where = ["1=1"]; params = {}
        if dt_from: where.append("created_at >= :df"); params["df"] = dt_from
        if dt_to:   where.append("created_at <= :dt"); params["dt"] = dt_to
        if kind:    where.append("kind = :kind");       params["kind"] = kind

        if by == "day":
            sql = text(f"""
                SELECT date_trunc('day', created_at)::date AS day, COUNT(*) AS n
                FROM reports
                WHERE {" AND ".join(where)}
                GROUP BY 1 ORDER BY 1
            """)
            w.writerow(["day","reports"])
        elif by == "kind":
            sql = text(f"""
                SELECT kind::text AS kind, COUNT(*) AS n
                FROM reports
                WHERE {" AND ".join(where)}
                GROUP BY 1 ORDER BY 1
            """)
            w.writerow(["kind","reports"])
        else:  # day_kind
            sql = text(f"""
                SELECT date_trunc('day', created_at)::date AS day, kind::text AS kind, COUNT(*) AS n
                FROM reports
                WHERE {" AND ".join(where)}
                GROUP BY 1,2 ORDER BY 1,2
            """)
            w.writerow(["day","kind","reports"])

        res = await db.execute(sql, params)
        for r in res.fetchall():
            w.writerow(list(r))

    else:  # events
        tabs = ["incidents","outages"] if table in (None,"both","") else [table]
        # on agr√®ge en UNION ALL puis regroupement Python
        rows = []
        for tname in tabs:
            where = ["1=1"]; params = {}
            if dt_from: where.append("started_at >= :df"); params["df"] = dt_from
            if dt_to:   where.append("started_at <= :dt"); params["dt"] = dt_to
            if kind:    where.append("kind = :kind");       params["kind"] = kind
            if status in ("active","restored"):
                if status == "active": where.append("restored_at IS NULL")
                else: where.append("restored_at IS NOT NULL")

            sql = text(f"""
                SELECT
                  date_trunc('day', started_at)::date AS day,
                  kind::text AS kind,
                  CASE WHEN restored_at IS NULL THEN 'active' ELSE 'restored' END AS status,
                  started_at, restored_at
                FROM {tname}
                WHERE {" AND ".join(where)}
            """)
            res = await db.execute(sql, params)
            rows.extend(res.fetchall())

        # regroupement
        from collections import defaultdict
        agg = defaultdict(lambda: {"n":0, "dur_sum":0.0, "dur_min":None, "dur_max":None})
        for r in rows:
            day = r.day
            kindv = r.kind
            statusv = r.status
            if by == "day":
                key = (str(day),)
            elif by == "kind":
                key = (kindv,)
            elif by == "day_kind":
                key = (str(day), kindv)
            else:
                key = (str(day), kindv, statusv)
            agg[key]["n"] += 1
            if r.started_at and r.restored_at:
                dur = (r.restored_at - r.started_at).total_seconds() / 60.0
                agg[key]["dur_sum"] += dur
                agg[key]["dur_min"] = dur if agg[key]["dur_min"] is None else min(agg[key]["dur_min"], dur)
                agg[key]["dur_max"] = dur if agg[key]["dur_max"] is None else max(agg[key]["dur_max"], dur)

        # header & rows
        if by == "day":
            w.writerow(["day","events","avg_duration_min","min_duration_min","max_duration_min"])
        elif by == "kind":
            w.writerow(["kind","events","avg_duration_min","min_duration_min","max_duration_min"])
        elif by == "day_kind":
            w.writerow(["day","kind","events","avg_duration_min","min_duration_min","max_duration_min"])
        else:
            w.writerow(["day","kind","status","events","avg_duration_min","min_duration_min","max_duration_min"])

        for key, val in sorted(agg.items()):
            avg = ""
            if val["dur_sum"] > 0 and val["n"] > 0:
                # moyenne sur √©l√©ments avec dur√©e (approx via dur_sum / n)
                avg = round(val["dur_sum"] / val["n"], 2)
            row = list(key) + [val["n"], avg,
                               round(val["dur_min"],2) if val["dur_min"] is not None else "",
                               round(val["dur_max"],2) if val["dur_max"] is not None else ""]
            w.writerow(row)

    buf.seek(0)
    return StreamingResponse(buf, media_type="text/csv",
        headers={"Content-Disposition": "attachment; filename=aggregated.csv"})

from fastapi import status

class AckIn(BaseModel):
    kind: str
    lat: float
    lng: float
    responder: Optional[str] = "firefighter"

@router.post("/responder/ack", status_code=status.HTTP_201_CREATED)
async def responder_ack(
    p: AckIn,
    request: Request,
    db: AsyncSession = Depends(get_db),
    token: Optional[str] = Query(None)
):
    # auth tr√®s simple: header x-admin-token OU token=? (RESPONDER_TOKEN)
    ok = False
    if ADMIN_TOKEN and request.headers.get("x-admin-token","").strip() == ADMIN_TOKEN:
        ok = True
    if not ok and RESPONDER_TOKEN and (token or "").strip() == RESPONDER_TOKEN:
        ok = True
    if not ok:
        raise HTTPException(status_code=401, detail="unauthorized")

    K = (p.kind or "").strip().lower()
    if K not in {"traffic","accident","fire","flood","power","water"}:
        raise HTTPException(400, "invalid kind")

    try:
        await db.execute(
            text("""
              INSERT INTO responder_claims(kind, center, responder, created_at)
              VALUES (:k, ST_SetSRID(ST_MakePoint(:lng,:lat),4326)::geography, :r, NOW())
            """),
            {"k": K, "lng": p.lng, "lat": p.lat, "r": (p.responder or "firefighter")}
        )
        await db.commit()
        return {"ok": True}
    except Exception as e:
        await db.rollback()
        raise HTTPException(500, f"ack failed: {e}")
    
# ---------- ZONES D‚ÄôALERTE (lecture) ----------
# routes_alert_zones.py
import os
from fastapi import APIRouter, Query, HTTPException, Depends
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import text
from typing import Optional
from ..db import get_db  # adapte si besoin

@router.get("/alert_zones")
async def alert_zones(
    kind: str = Query(..., description="fire|traffic|accident|flood|power|water"),
    lat: float = Query(..., ge=-90, le=90),
    lng: float = Query(..., ge=-180, le=180),
    radius_km: float = Query(1.0, ge=0.1, le=50),
    hours: int = Query(int(os.getenv("ALERT_WINDOW_HOURS", "3")), ge=1, le=72),
    min_count: int = Query(int(os.getenv("ALERT_MIN_REPORTS", "3")), ge=2, le=50),
    cell_m: int = Query(int(os.getenv("ALERT_RADIUS_M", "150")), ge=50, le=1000),
    db: AsyncSession = Depends(get_db),
):
    k = (kind or "").strip().lower()
    if k not in ALLOWED_KINDS:
        raise HTTPException(status_code=400, detail="invalid kind")


    # ~150 m ‚Üí degr√©s
    cell_deg = max(0.0003, min(0.01, cell_m / 111_000.0))

    sql = text("""
      WITH me AS (
        SELECT ST_SetSRID(ST_MakePoint(:lng,:lat),4326)::geography AS g
      ),
      base AS (
        SELECT id, kind, created_at, (geom::geography) AS gg
        FROM reports
        WHERE LOWER(TRIM(kind::text))   = :kind
          AND LOWER(TRIM(signal::text)) = 'cut'
          AND created_at > NOW() - make_interval(hours => :hours)
          AND ST_DWithin((geom::geography), (SELECT g FROM me), :rad_m)
      ),
      cells AS (
        SELECT
          kind,
          ST_SnapToGrid((gg::geometry), :cell_deg, :cell_deg) AS grid,
          gg
        FROM base
      ),
      grouped AS (
        SELECT
          kind,
          grid,
          COUNT(*) AS count,
          ST_Centroid(ST_Collect(gg::geometry)) AS center_geom
        FROM cells
        GROUP BY kind, grid
        HAVING COUNT(*) >= :min_count
      ),
      zones AS (
        SELECT
          kind,
          count::int AS count,
          ST_Y(center_geom) AS lat,
          ST_X(center_geom) AS lng
        FROM grouped
      )
      SELECT z.kind, z.count, z.lat, z.lng
      FROM zones z
      WHERE NOT EXISTS (
        SELECT 1
        FROM acks ak
        WHERE LOWER(TRIM(ak.kind::text)) = LOWER(TRIM(z.kind::text))
          AND ST_DWithin(
            (ST_SetSRID(ST_MakePoint(z.lng, z.lat),4326)::geography),
            (ak.geom::geography),
            :ack_r
          )
      )
      ORDER BY z.count DESC
      LIMIT 50
    """)


    params = {
        "kind": k,
        "lng": lng, "lat": lat,
        "rad_m": float(radius_km) * 1000.0,
        "hours": int(hours),
        "cell_deg": float(cell_deg),
        "min_count": int(min_count),
        "ack_r": float(cell_m),
    }

    try:
        rs = await db.execute(sql, params)
        rows = rs.mappings().all()
    except Exception as e:
        await db.rollback()
        raise HTTPException(status_code=500, detail=f"alert_zones failed: {e}")

    return [
        {"kind": r["kind"], "lat": float(r["lat"]), "lng": float(r["lng"]),
         "radius_m": int(cell_m), "count": int(r["count"])}
        for r in rows
    ]



# ---------- PRISE EN CHARGE POMPIER / ADMIN (√©criture) ----------
class AckIn(BaseModel):
    kind: str
    lat: float
    lng: float
    user_id: Optional[str] = None    # optionnel: pour tra√ßabilit√©

@router.post("/fire_ack")
async def fire_ack(
    p: AckIn,
    request: Request,
    db: AsyncSession = Depends(get_db),
):
    # simple auth pompier/admin via x-admin-token (m√™me logique que /admin/*)
    admin_hdr = (request.headers.get("x-admin-token") or "").strip()
    tok = (os.getenv("ADMIN_TOKEN") or os.getenv("NEXT_PUBLIC_ADMIN_TOKEN") or "").strip()
    if not tok or admin_hdr != tok:
        raise HTTPException(status_code=401, detail="invalid admin token")

    k = (p.kind or "").strip().lower()
    if k not in {"traffic","accident","fire","flood","power","water"}:
        raise HTTPException(400, "invalid kind")

    try:
        await db.execute(text("""
            INSERT INTO acks(kind, geom, user_id, created_at)
            VALUES (:k, ST_SetSRID(ST_MakePoint(:lng,:lat),4326)::geography,
                    NULLIF(:uid,'')::uuid, NOW())
        """), {"k": k, "lng": p.lng, "lat": p.lat, "uid": (p.user_id or "")})
        await db.commit()
    except Exception as e:
        await db.rollback()
        raise HTTPException(500, f"fire_ack failed: {e}")

    return {"ok": True}

